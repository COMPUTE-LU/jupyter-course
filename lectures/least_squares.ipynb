{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nonlinear Regression in [`SciPy`](https://docs.scipy.org/doc/scipy/reference/)\n",
    "\n",
    "We often need to find a function $y=f(x,\\beta)$ of variable $x$ and $p$ unknown parameters $\\beta$ which fits a given set of $n$ predictor, {$x_1,...,x_n$}, and response, {$y_1,...,y_n$}, values.<br>\n",
    "The best fit can be obtained by minimizing the residual sums of squares (RSS) with respect to $\\beta$,\n",
    "\\begin{equation}\n",
    "\\mathrm{RSS}(\\beta) = \\sum_{n=1}^{\\infty} \\left[ y_i - f(x_i,\\beta) \\right ] ^2.\n",
    "\\end{equation}\n",
    "For nonlinear functions, numerical optimization methods are needed to minimize RSS and find the best-fit parameters, $\\hat{\\beta}$.<br>\n",
    "The most common numerical optimization method for nonlinear regression is the [Gauss-Newton method](https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm).<br>\n",
    "A summary measure of the model fit is the residual variance which is defined as the ratio of the minimum of RSS devided by the number of degrees of freedom:\n",
    "\\begin{equation}\n",
    "\\chi_R^2 = \\frac{\\mathrm{RSS}(\\hat{\\beta})}{n-p}.\n",
    "\\end{equation}\n",
    "Sometimes, we have several curves that we want to fit with the same function $f$. These curves have some parameters in common that we want to be determined on all the available data.<br>\n",
    "In this Notebook, we show how to perform least-sqares fits in `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize': [3.5, 3], 'font.size':8, 'legend.fontsize':8, 'figure.dpi': 150,\n",
    "                     'legend.handlelength':1, 'legend.frameon':False,\n",
    "                     'xtick.major.size':6,'ytick.major.size':6,\n",
    "                     'xtick.minor.size':3,'ytick.minor.size':3,\n",
    "                     'xtick.direction':'out','ytick.direction':'out',\n",
    "                     'xtick.labelsize':8,'ytick.labelsize':8,\n",
    "                     'xtick.major.pad':2,'ytick.major.pad':2,\n",
    "                     'axes.linewidth':1,'axes.labelsize':10,})\n",
    "from cryptography.fernet import Fernet\n",
    "import base64\n",
    "def encrypt(string, key):\n",
    "    keygen = lambda x : base64.urlsafe_b64encode(x.encode() + b' '*(32 - len(x)))\n",
    "    cipher = Fernet(keygen(key))\n",
    "    return cipher.encrypt(string.encode())\n",
    "def decrypt(string, key):\n",
    "    keygen = lambda x : base64.urlsafe_b64encode(x.encode() + b' '*(32 - len(x)))\n",
    "    cipher = Fernet(keygen(key))\n",
    "    return print(cipher.decrypt(string.encode()).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Case Study: Time-Resolved Fluorescence Spectroscopy\n",
    "\n",
    "### SDS Micelles in the Presence of a Hydrophobic Fluorophore and a Fluorescence Quencher\n",
    "\n",
    "- **The micelle:**<br>\n",
    "    Sodium dodecyl sulfate (SDS) is an anionic surfactant with a hydrophobic tail of 12 carbon atoms and a hydrophilic sulphate head group. Due to its amphipatic nature, SDS self-assembles into micelles in aqueous solution. Micelle formation is a cooperative process which occurs in a narrow range of surfactant concentrations around the critical micellar concentration (CMC).<br>At concentrations below the CMC., surfactant molecules are mostly in the monomer state.<br>At the  (CMC), surfactant molecules form micelles with a well-defined aggregation number. The size distribution of the aggregates is rather narrow and depends on the relative dimensions of the head and tail groups.<br>Above the CMC, the number of micelles increases while the size of the micelles stays the same.  \n",
    "<table><tr><td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Sodium_dodecyl_sulfate.svg/2880px-Sodium_dodecyl_sulfate.svg.png\" width=\"300\"></td><td><img src=\"https://marcello-sega.github.io/pytim/_images/micelle2.png\" width=\"150\"></td></tr><table>    \n",
    " \n",
    "- **The fluorophore:**<br>Pyrene is a hydrophobic fluorescent molecule.<br>In an aqueous SDS solution at [SDS]>CMC, pyrene tends to partition into the hydrophobic interior of the micelles.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Pyrene.svg/190px-Pyrene.svg.png\" width=\"150\" align=\"center\">\n",
    "\n",
    "- **The quencher:**<br>Benzophenone is a hydrophobic compound which also tend to be in the micelles where it quenches the fluorescence of pyrene (it makes it decay faster). \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Benzophenon.svg/1200px-Benzophenon.svg.png\" width=\"150\" align=\"center\">\n",
    "\n",
    "- **The experiment:**\n",
    "We measure the number of photons emitted by pyrene molecules in SDS micelles for increasing time intervals after the excitation pulse. The fluorescence intensity decay of pyrene following an excitation pulse is given by<br><br>\n",
    "\\begin{equation}\n",
    "F(t)=F(0)\\exp(-t/\\tau_0)\n",
    "\\end{equation}<br>\n",
    "where $\\tau_0$ is the lifetime of the fluorophore.\n",
    "In the presence of $j$ benzophenone molecules per micelle, the lifetime of pyrene decreases to\n",
    "\\begin{equation}\n",
    "\\tau_j = \\frac{\\tau_0}{1 + j k_q \\tau_0}.\n",
    "\\end{equation}\n",
    "where $k_q$ is the quenching constant.<br>\n",
    "The distribution of quenchers in the micelles follows Poisson's statistics, therefore the fraction of micelles containing $j$ benzophenone molecules is given by\n",
    "\\begin{equation}\n",
    "P(j) = \\frac{m^j}{j!}\\exp{(-m)}\n",
    "\\end{equation}\n",
    "where $m$ is the average number of benzophenone molecules per micelle.<br>\n",
    "The fluorescence intensity decay of pyrene in the presence of benzophenone is given by the weighted average over the difstribution of micelles with different numbers of quenchers<br><br>\n",
    "\\begin{equation}\n",
    "F(t)=F(0)\\sum_{j=0}^{\\infty} P(j) \\exp{(-t/\\tau_j)}=F(0)\\exp\\left\\{-t/\\tau_0-m\\left [1-\\exp{(-k_qt)}\\right ]\\right\\},\n",
    "\\end{equation}<br>\n",
    "where we have used the converging series\n",
    "\\begin{equation}\n",
    "\\sum_{j=0}^{\\infty} \\frac{x^j}{j!} = \\exp{(x)}.\n",
    "\\end{equation}\n",
    "\n",
    "We used a solution 70 mM SDS and 10 $\\mu$M pyrene in 5mM phosphate buffer at pH 7.4. The emission wavelength of the spectrometer is set to 391 nm, corresponding to the maximum fluorescence intensity for pyrene.\n",
    "- First, we measure the intensity decay of the solution in the absence of quencher. A least-squares fit on this curve yields $F(0)$ and the pyrene lifetime, $\\tau_0$. \n",
    "- Then, we measure intensity decays for increasing concentrations of benzophenone, _i.e._, $[$quencher$]$ $=$ 0.1, 0.2, 0.5, 1 e 1.5 mM.\n",
    "We perform a global fit on these five curves. Each corve has a different average number of quencher molecules per micelle, $m$, and common parameters $F(0)$, $\\tau_0$, and $k_q$. \n",
    "\n",
    "Since the excitation pulse occurs in a shorter time scale compared to the decay of the fluorescence signal, we disregard the width of the excitation pulse in our analysis. In the least-squares fitting procedures, we weight each photon count, $F(t)$, by its error which is simply $\\sqrt{F(t)}$ because fluorescence counts follow Poisson's statistics.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The data are tab-separated values (TSV) files (collected at [Prof. L. Stella lab](http://www.stc.uniroma2.it/physchem/stella.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%cat 'data/fluorescence/quencher_0.0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%ls 'data/fluorescence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the intensity decays for increasing concentrations of quencher.<br>\n",
    "The intensity signal decays faster with increasing concentration of benzophenone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    t,F = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=True, skiprows=9)\n",
    "    plt.errorbar(t, F, np.sqrt(F), lw=0, marker='o', label='{:1.1f}'.format(conc)+' mM',\n",
    "                 ms=2, elinewidth=1., capsize=2, capthick=1., mfc='w')\n",
    "plt.legend(title='[quencher]',labelspacing=.7,loc=1)\n",
    "plt.ylabel('$F(t)$  /  counts'); plt.xlabel('$t$  /  ns'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use boolean masking to select the data points after the excitation pulse and we shift the x values so that they measure the time intervals from the excitation pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    d = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=False, skiprows=9)\n",
    "    d = d[ d[:,0] > d[d[:,1]==d[:,1].max(), 0] ] # points before the intesity max are discarded\n",
    "    plt.errorbar(d[:,0]-d[0,0], d[:,1], np.sqrt(d[:,1]), lw=0, marker='o', label='{:1.1f}'.format(conc)+' mM',\n",
    "                 ms=2, elinewidth=1., capsize=2, capthick=1., mfc='w')\n",
    "plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A convenient way to save data sets to file is to use [pickling](https://docs.python.org/3/library/pickle.html). We create a  `pandas` DataFrame and we save it as a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# first we generate a dictionary\n",
    "data = {}\n",
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    d = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=False, skiprows=9)\n",
    "    d = d[ d[:,0] > d[d[:,1]==d[:,1].max(), 0] ] # points before the intesity max are discarded\n",
    "    data[conc] = { 't': d[:,0]-d[0,0], 'F': d[:,1], 'Ferr': np.sqrt(d[:,1]) }\n",
    "# a dataframe is generated from the dictionary\n",
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.to_pickle('data/fluorescence.p')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The curve for $[$quencher$]$=0 mM is fitted to a single exponential decay function using [`optimize.least_square`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html) which requires the following arguments:\n",
    "- the function which computes the vector of residuals\n",
    "- the initial parameters\n",
    "- the data\n",
    "- the lower and the upper bounds of the fitting parameters<br>\n",
    "\n",
    "`\n",
    "least_squares(function_to_minimize, initial_params, \n",
    "    [x, y, yerr], bounds=[(lower_bounds),(upper_bounds)])\n",
    "`\n",
    "\n",
    "`least_squares` returns an OptimizeResult object containig the best-fit parameters (`x`), the residuals calculated for the best-fit parameters (`fun`), RSS/2 (`cost`), and the modified Jacobian matrix, $J$, at the solution (`jac`), $J^T J$ is a [Gauss-Newton approximation of the Hessian](https://reference.wolfram.com/language/tutorial/UnconstrainedOptimizationGaussNewtonMethods.html) of the residual function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# we load the data from the pickle file\n",
    "d = pd.read_pickle('data/fluorescence.p')[0.0]\n",
    "args = [ d['t'], d['F'], d['Ferr'] ] # list containing x, y, yerr\n",
    "\n",
    "# we define the exponential decay\n",
    "def exp_decay(x, param):\n",
    "    return param[0] * np.exp( - x / param[1] ) \n",
    "\n",
    "# we define the function that calculates the residuals\n",
    "def residuals(param, *args):\n",
    "    return ( args[1] - exp_decay(args[0], param) ) / args[2] # residuals weighted by the error on y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# we fit the data\n",
    "res = least_squares(residuals, x0=[3000,150], args=args, bounds=[(6,150),(3500,200)])\n",
    "\n",
    "# we plot the data\n",
    "plt.errorbar(args[0],args[1],args[2],lw=0,marker='o',ms=1,elinewidth=1.,capsize=3,capthick=1.,\n",
    "             color='k',alpha=0.3)\n",
    "\n",
    "# we plot the fitting curve\n",
    "plt.plot(args[0],exp_decay(args[0],res['x']),lw=3,color='r')\n",
    "\n",
    "# we set the log scale for the y-axis\n",
    "plt.yscale('log')\n",
    "plt.ylabel('$\\ln [F(t)]$  /  counts'); plt.xlabel('$t$  /  ns'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Is one of the convergence criteria satisfied?', res.success) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best-fit parameters are',res.x[0],'and',res.x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "table = r\"\"\"| Parameter     | Value         | Error |\n",
    "| :---------------- |:-------------:| :----:|\n",
    "| $F(0)$ (counts)   | %.2f          | ?     |\n",
    "| $\\tau_0$ (ns)     | %.2f          | ?     |\"\"\"\n",
    "\n",
    "display.Markdown(table % tuple(res.x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\chi_R^2 = \\frac{\\mathrm{RSS}(\\hat{\\beta})}{n-p}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The residual variance is', 2 * res.cost / (res.fun.size - res.x.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can check whether the model is appropriate and we have obtained a good fit by comparing the Gaussian with $\\sigma=1$ and $\\mu=0$ with the histogram of the residuals at solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(res.fun.min(),res.fun.max()+1,100)\n",
    "plt.plot(bins, np.exp(-bins*bins/2)/np.sqrt(2*np.pi), label='Gaussian', color='k')\n",
    "plt.hist(res.fun, bins, lw=2, histtype='step', density=True, label='residuals', color='r')\n",
    "plt.xlabel('Residuals'); plt.ylabel('Probability Distribution'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The uncertainties on the best-fit parameters are estimated from the variance-covariance matrix.<br>\n",
    "Here is the implementation in the function [`optimize.curve_fit`)](https://github.com/scipy/scipy/blob/2526df72e5d4ca8bad6e2f4b3cbdfbc33e805865/scipy/optimize/minpack.py#L739) which uses `least_squares` under the hood.\n",
    "Further information [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) and [here](http://scipy-cookbook.readthedocs.io/items/FittingData.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "# copied from curve_fit \n",
    "def error_analysis(res):\n",
    "    rss = 2 * res.cost  # res.cost is half sum of squares!\n",
    "    s_sq = rss / (res.fun.size - res.x.size) # residual variance or reduced chi squared\n",
    "    # Do Moore-Penrose inverse discarding zero singular values.\n",
    "    _, s, VT = svd(res.jac, full_matrices=False)\n",
    "    threshold = np.finfo(float).eps * max(res.jac.shape) * s[0]\n",
    "    s = s[s > threshold]\n",
    "    VT = VT[:s.size]\n",
    "    pcov = np.dot(VT.T / s**2, VT) * s_sq # variance-covariance matrix\n",
    "    return np.sqrt(np.diag(pcov)), s_sq # errors on the params are the diagonal elements of pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "table = r\"\"\"| Parameter     | Value         | Error |\n",
    "| :---------------- |:-------------:| :----:|\n",
    "| $F(0)$ (counts)   | %.0f          | %.0f  |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f  |\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_and_err = np.repeat(res.x, 2)\n",
    "p_and_err[1::2] = error_analysis(res)[0]\n",
    "print('Reduced chi squared:',error_analysis(res)[1])\n",
    "display.Markdown(table % tuple(p_and_err) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "##  Task 1\n",
    "- Fit the data for $[$quencher$]$ $=$ 0 using [`optimize.curve_fit`)](https://github.com/scipy/scipy/blob/2526df72e5d4ca8bad6e2f4b3cbdfbc33e805865/scipy/optimize/minpack.py#L739).\n",
    "- Plot the data and the function with the best-fit parameters.\n",
    "- View a markdown table with the best-fit parameters and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = 'gAAAAABcBDlaRCOfnjUcmToYnEdOciuqiLV8TVxoLmyI1YiwAU8Ux_kcXVgFb-AZ87LV3DggpValGCTdAZ3kfijtjcB-271i1d5gF-7tQzM_XqQpLoChhrOE31dym4nOheTkkMafgMtu5JTS2Xg2WD4ziYF1H4ri2E0zlV_yIdmbJ5X14f6caG3NFES5Y8FLuKBpJpuSYDoCOg3DsRH-_Lo3ZHpLHOe2iKNMyroVgdQ-W44SzRqucnkRv4bK0L3EUcBUHrW-fFhj6veqYTi464yVkNuLGQza0QzEGFvQu8QuBQMaggNw97dllsHpfSCoLh4sCwS6oe9IJLfxHBgusgwQnNcpahJcINmnFMQnRNsQn7bujSnRpEUeORZeQq2S_7OuKKZl2tpJrWtpyRrIophfTmf7fV7daORiXU2W9KAS0Ym0Kft10BfIp_XK7MsbDWHjc4CCj-U6SEx4Mn091ds8Qy-wHsTGxlAAnCLOY2irqVQYuYljzh7oq7iRWYk_sxGCddwSxMX2AsotclVz677gQWZHSHn-2lRVcL8xGQiattT2MicC0Gk2ukG2WdXs_cZHB3J7iBU2ZmMv00ZvYK7QWdEW-CCUhxKPb9daAhCURpXyatMKuZnP8KtCO8nJ9ITluNGFy-6dZ0FdplO9Y7wG7MHoXWJKoSlbXzMMZto5LK1AC_DLEM0ImzLyiQThwBFBpU0DuD1QRyEs4AzF1k3BS_ifpSZ-NXaF2j_pJneJkt7k64tEH7D1Ea9NsD1tLYmU2itKQwHh9BVdFRBJwYgBEoQ-oJAvh91gQxgJLi9gzU4I_kVEZnvnH-THrQ2xOAWdKsfCxXE5gBYNG5thCCsBllUUcB9h4jlVsuBCnx2u1hbrLq7glmWZOrfxUgMjvsYMi_6o5S0qW0XdFz0CjdPJ_E44CDSG30i-4XUE4z4AyrXsZP-8ViBY2vJmiGPNzLhiEv3c6URuS6Qns_EPvGwZQEnLDTeAtLY2owHeEva_gIGkT1U2-KK4CZXESBf9v0yv5ABptx3l_WhxqPIEzCbWvv9j_AU8f6-QT8eQR7a-akKrEaEqR9s_2LAAEN09nAmDHBcIJaKlfp-Zw00MG5UGBKERA4v1V74QoRNHunD3Cq-ZS8ckAiq9F3Tt4Hs0hLghSeujwLgsiQ95G8ktYKIyhnUxgXbwNdMcH5ulCEEgeeUVa6U3XadtVli3KUtKd3AaDGtlpoOZ9LqH6NSkI_mOk2BXiL9ZlVSM4hE_fz3gEt7fCJWd0VnxKGLiKuBNWsj7yc6dSZG6sdHwmVhGHmeY1pMXCN8lN-D3D1yOyzY5eYDtpkhGeJeNSC1Qbklx__ZuHUSbgX94g4tBL9XFnj4m6uSmfntk9KupnX3FWXV_oPVEyBbhEzU='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypt(answer,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Global Least-Squares Fit\n",
    "\n",
    "Now we performa a global fit of the 5 curves with increasing [quencher]: $F(0)$, $\\tau_0$, and $k_q$ are global parameters whereas $m$ depends on [quencher].\n",
    "* We create 3 lists (for x, y, and yerr) each containing 5 `NumPy` arrays (for the 5 curves).\n",
    "* We create a list called args containing the 3 lists (allx, ally, allyerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/fluorescence.p')\n",
    "allx = []; ally = []; allyerr = [] # three empty lists\n",
    "for conc in data.columns:\n",
    "    allx.append(data[conc]['t']); ally.append(data[conc]['F']); allyerr.append(data[conc]['Ferr'])\n",
    "args = allx, ally, allyerr # args is a list of three lists containing 5 numpy arrays\n",
    "param0 = [3000, 160, 0.04, 0] + [0.5]*4 # initial parameters\n",
    "lbound = [0, 0, 0] + [0]*5              # lower bound\n",
    "ubound = [4000, 200, 1, 1e-5] + [3]*4   # upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the residuals function, we calculate the vector of residuals for each curve which appended to a single 1D `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# we define the function for the intensity decay\n",
    "def decay(x, param):\n",
    "    return param[0]*np.exp( - x/param[1] + param[3]*np.expm1(-param[2]*x) ) \n",
    "# we define the function that calculates the least squares\n",
    "def residuals(p, *args):\n",
    "    residuals = np.empty(0)\n",
    "    for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        r = ( args[1][i] - decay(args[0][i], param) ) / args[2][i]\n",
    "        residuals = np.append(residuals, r)\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "res = least_squares(residuals, x0=param0, args=args, bounds=[lbound,ubound])\n",
    "c = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "p = res['x']\n",
    "for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        plt.fill_between(args[0][i],args[1][i]-args[2][i],args[1][i]+args[2][i],alpha=.7)\n",
    "        plt.plot(args[0][i],decay(args[0][i],param),lw=1,color=c[i],label='{:1.1f}'.format(data.columns[i])+' mM')\n",
    "plt.yscale('log'); plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$\\ln F(t)$ / counts'); plt.xlabel('$t$ / ns'); \n",
    "print('Reduced chi squared:',error_analysis(res)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using markdown to view the results in a table, we create a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'Value':res.x,'Error':error_analysis(res)[0]},\n",
    "             index=['$F(0)$ (counts)','$\\tau_0$ (ns)','$k_q$ (ns$^{-1}$)','$m_0$','$m_1$','$m_2$','$m_3$','$m_4$'],\n",
    "            columns=['Value','Error'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Task 2 \n",
    "Take the logarithm of each curve and perform a global fit to $\\ln F(t) = \\ln F(0) - t/\\tau_0 + m [\\exp(-k_q t) -1]$ using `least_square`.\n",
    "1. Modify the `NumPy` arrays in args[1] by taking the `np.log`.\n",
    "```.py\n",
    "data = pd.read_pickle('data/fluorescence.p')\n",
    "allx = []; ally = []; allyerr = [] # three empty lists\n",
    "for conc in data.columns:\n",
    "    allx.append(data[conc]['t']); ally.append(data[conc]['F']); allyerr.append(data[conc]['Ferr'])\n",
    "args = allx, ally, allyerr # args is a list of three lists containing 5 numpy arrays\n",
    "for i in range( data.columns.size ):\n",
    "    args[1][i] = ?\n",
    "    args[2][i] = ? \n",
    "```\n",
    "2. Modify the `NumPy` arrays in args[2] according to the error propagation rule: error$(\\ln F)$ = error($F$) / $F$.\n",
    "3. Define a new fitting function for the linearized equation. \n",
    "4. Fitting and plotting can be carried out exactly as in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/fluorescence.p')\n",
    "allx = []; ally = []; allyerr = [] # three empty lists\n",
    "for conc in data.columns:\n",
    "    allx.append(data[conc]['t']); ally.append(data[conc]['F']); allyerr.append(data[conc]['Ferr'])\n",
    "args = allx, ally, allyerr # args is a list of three lists containing 5 numpy arrays\n",
    "param0 = [8, 160, 0.04, 0] + [0.5]*4 # initial parameters\n",
    "lbound = [0, 0, 0] + [0]*5              # lower bound\n",
    "ubound = [10, 200, 1, 1e-5] + [3]*4   # upper bound\n",
    "\n",
    "# we modify y and yerr in args\n",
    "for i in range( data.columns.size ):\n",
    "    args[2][i] = args[2][i]/args[1][i] \n",
    "    args[1][i] = np.log(args[1][i])\n",
    "\n",
    "# we define the function for the linearized intensity decay\n",
    "def lin_decay(x, param):\n",
    "    return param[0] - x/param[1] + param[3]*np.expm1(-param[2]*x)\n",
    "\n",
    "# we define the function that calculates the least squares\n",
    "def residuals(p, *args):\n",
    "    residuals = np.empty(0)\n",
    "    for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        r = ( args[1][i] - lin_decay(args[0][i], param) ) / args[2][i]\n",
    "        residuals = np.append(residuals, r)\n",
    "    return residuals\n",
    "\n",
    "res = least_squares(residuals, x0=param0, args=args, bounds=[lbound,ubound])\n",
    "c = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "p = res.x\n",
    "for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        plt.fill_between(args[0][i],args[1][i]-args[2][i],args[1][i]+args[2][i],alpha=.7)\n",
    "        plt.plot(args[0][i],lin_decay(args[0][i],param),lw=1,color=c[i],label='{:1.1f}'.format(data.columns[i])+' mM')\n",
    "plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$\\ln F(t)$  /  counts'); plt.xlabel('$t$  /  ns'); \n",
    "\n",
    "table = r\"\"\"| Parameter     | Value         | Error     |\n",
    "| :---------------- |:-------------:| :-------:|\n",
    "| $F(0)$ (counts)   | %.3f          | %.3f     |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f     |\n",
    "| $k_q$ (ns$^{-1}$) | %.4f          | %.4f     |\n",
    "| $m_0$             | %.3f          | %.3f     |\n",
    "| $m_1$             | %.3f          | %.3f     |\n",
    "| $m_2$             | %.3f          | %.3f     |\n",
    "| $m_3$             | %.3f          | %.3f     |\n",
    "| $m_4$             | %.3f          | %.3f     |\"\"\"\n",
    "p_and_e = np.repeat(res['x'],2)\n",
    "p_and_e[1::2] = error_analysis(res)[0]\n",
    "print('Reduced chi squared:',error_analysis(res)[1])\n",
    "display.Markdown(table % tuple(p_and_e) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = 'gAAAAABcBEC192GhbrC-Qql12nZBxo_1HCg9OO6D2B0lBS-mueXILEKTV9W4h05CMZR8PrxUA3cM0CKOaJJFhH24ffYn7DbKp6KGni6E77LZpK3kSAzdpnCytW1A8Eu2zRaDA_KqBlGR_4yq1dpBQ0mIfMHBJt1C1tbmQwWInyjmQXY79hxWvAzKpUiQlQ0OLyNsL_tSN-QMcfChVd44sZ2xXHsYV301b33VRGp8yCr-JfMHmYncDNfVMb8I-KhRCBccWfIcgitN-vfYYsk3vBJLlSMPEaGTVNexYTTKqcPXADNu86-VV0KwdqCRyl-7nW_Z0-dNkEai6GW2AdW3b3wPh9c8GGp_I83RwngcBxOff6mc4P8izJpBN6483zo-KwoGd3wtNuVI3tpCoU9FLdPTkkG9R66W2otPFAdGXvc0rRHz-F-rwvXYw4uqn9M2ay602omP6p9yHo-SVTvN5n5LacazXBLsf0-DLPKj0Up8qH1ErCcdWTcvUg4nPaUp12ErrLE2IlasopMFjCGxEZVVeuB9dKgO6PZOo5G1SDBdjKFGi0MJyXCMNqUAWl49uVGLGzpy-GvBgIa_ZHkQJiaKxFjD5P0UevgxP8RGCgT_RokeYC9owRGErQxFdEQsr4oHTMhV-RisvHjmDRVmxSejUfNy0rln5cVIXxX8TFjc9F_EMDsEapaY0KTIHzCoODyTF2Kk1ZuzJnMkPOVXp8y3wHbv8kHKPmSzCvUJ6fk4MmQgSjHWqjRzKMK6skwmND8owUurwPeK5SMSH4WLRYm26llOxLtbcx-sMIivnuqNMfj7uE3aDhme2PXhoG9G4D_jn5xfHyzxNZ9qwF-ddEUgYAkdCrBrOWrdJQmPRKeuhcHp_Pt8NUcfwlfO77aXBnjmjgvLr06gi0qeSZXeHJxOV__YnhVP9ajQGBLwg1edT-S_4swJBpu3uIaGiuQtmxpdxOAN2PsaSMPPTIsFNQG0jgjrOFzotJgfcCfqIhlfCY3kE5fmIyVy15neHQTLeSeu8IObxOQCJHyqPID9sTf1-xU9h4uF3dN5ckiJGAjbAIKn1Z6WbgS65GsDbMKw29E4R2xbbfnWkP-6LwbpH1fulv13laiZqUJyRIhSy17AhphAU0tdCK95nWOKyFX0Iv3q4Gwdq0gac2gxh4vLa2XmTs2a-KS7dTGcSyUbA7ph5KMWTqRyXPHmizRfgRgTj4x5NFmeQLto6_CWz_msuQ_DWDGlL8EJVj-DHHx1eOh-1y8x393ngZ_g9yXGKYsbbgineUPtjIreks4PoBLMG6zsysCA5sQIpekrApdHTVHNGOuKG6cw27P744ojoW2DZtgX1yMBm4SNhvL82j_awGKtWDjSFwblQLp1niA2WdjLaz3corJCURAkLNLdxUZO0gH6SGk35hSQxH7jXcql1Abu22R180wEbHFDNc4OJrAP28xxg39_K3Bc_UYC1RSv_9Pjh-NViQHi7BGHre3QujEtAfbKGeojbNQz3GHxIsVqhB6jfP1Q4H99ZY_Es_AtKWt7TrraUkgnHcJRQ_AZzsxa5qBseNRzQhWOWX9ao3wHwaAFe9jE1slGgtL4Ab5H3boN1zmui-DUi41z5WddaEdjfT2UFoR-eicnfJUToVV02vaNp9Mf_MDRmQUMA0IY-3yxMMDpTbo6xcn-lGcHiyPYAywEf3_r0PxXcCL_9rDn3ShccNzteE0jGccldqhKBy-fHGh3d5qcPjwf6H6_jfwF4rrBYsLvTtpV0A7lLQNxzcKsr-vvYUor2B6_C9lLevPxjFKnYFuGs0KMP-aIlJrQmfC2iNYDQbu3B57WfYqwDURLe7Bg7XnFg1SDOa_x6dmOUdUOg-idQBuV-jHgr-lhKNSjH5W7vcnj-Om4w4phqlvh4unA-yD3tu_0zb-XycJ-mgotBPtNT0XE2j62hKGINlGVnSnKEVhqtkwRrMfa1orfbLEHGmOxgNkYh9epKAPLWexcKB088Hefs3EpXd6u0cm9SjBfFP8vtRLX8ft3HSQzPFToitNkP5kbhzELtSRl4G2_LZ65QdRNy9kBOATLMWXBqyFXK-iil655xBmZf-QOmIXePLcjbfjgCOK0v4zTiXMzHLOBACQAj35zRUbp8dJRu5dcWndOKd6s0iXHdD8_WfpFe6b3dF36xh8Q1md_m-FfV5mUEoZFggv5WLUIjZ653PT4nGF-VRZN7HQgES93sJrmt2lmgTPoVCBkNPPcHWjebTbcgYlYsYk4YRSFYj4BUdUuYdtoO0OK7rPsrYlFb5pDMPxqayoN9lN4cU36M8XlssINeMybpjB_KeXlwrosDf2tQkFJ-nsHMLtuwG-cQqcas_BCxRP3x95LuRD4tVX8fpsmS7MIVgugIpvmwmJ9bOJtg02aWNgFulK4reXN8FuJL8IoT8VZMMbNNyQeRLsAuT1QE8Y4s7FVTBpt6kDN-3A46OuHO6XkHfHvZmUgbflqgmz7bSGMICiNm_LXF1PtvISfp3l7klh_wR3drYeUEVyq0OMdcxN-KMbOpRmm3vLUCh8p6RBOmFHRd2hnSPayG_2ld5zh3Tw-1NeA224w6Gr5vjOK3tYgobS4ritVERPZSt58L5wk3TpBSvspBLCbpgcBsHexbOSeAjIIC_0YwMWUFjgXXDq8h9F2QaxLeaRbX9HdRjIkKbWJ4f-2UQoSwvAKbeyEkmk-tEDbZQH3JqIbml9uspy9DOA_eFpOvMpE9aodJWizGYFMe_056SI7h4aNgeQAiEB2FxCgD77IFeky3PyNkW5Q4lfw__TKQwf1QREJOSsCwQoX53j6LoF5jz8KygE3xwiVsYMF8jPMY9SWWrmyER8H2CnmCzU19e7nSqFZ4qnDMYLfKQKUlAlCARFuPYlRhJ0LQgVsPVpfoqQSa2GD5ADFsEBCXJqTJMwQv79jvHUG1aGCLg94UW1cx6X4A9QWcR0JIsXR_PTebQqX_lzKO-3U5bUuKo-qxRDq9z_UbsUX3h6uWaguU5suoE9xNCo-LA1-9-opNo8L8Dx4A_HIr6VH9CDWtcDkOCd0wnBEKhnl9Zso2TlbVOw7eGEtipRZUnJQ8mpsDcrxOHngrCZDI_CdNCtAZU5fnQje0A8='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypt(answer,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
