{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Least-Square Fitting with [`SciPy`](https://docs.scipy.org/doc/scipy/reference/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize': [8, 5], 'font.size':16, 'legend.fontsize':14, \n",
    "                     'legend.handlelength':1, 'legend.frameon':False,\n",
    "                     'xtick.major.size':8,'ytick.major.size':8,\n",
    "                     'xtick.minor.size':4,'ytick.minor.size':4,\n",
    "                     'xtick.direction':'in','ytick.direction':'in',\n",
    "                     'xtick.labelsize':14,'ytick.labelsize':14,\n",
    "                     'xtick.major.pad':5,'ytick.major.pad':5,\n",
    "                     'axes.linewidth':1.5,'axes.labelsize':16,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Case Study: Time-Resolved Fluorescence Spectroscopy\n",
    "\n",
    "<table><tr><td><img src=\"https://marcello-sega.github.io/pytim/_images/micelle2.png\" width=\"200\"><figcaption>A micelle</figcaption></td><td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Pyrene.svg/190px-Pyrene.svg.png\" width=\"170\"><figcaption>Pyrene</figcaption></td><td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Benzophenon.svg/1200px-Benzophenon.svg.png\" width=\"190\"><figcaption>Benzophenone</figcaption></td></tr><table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SDS Micelles in the Presence of a Hydrophobic Fluorophore\n",
    "Sodium dodecyl sulfate (SDS) is an anionic surfactant which self-assembles into micelles in aqueous solutions.\n",
    "At the critical micellar concentration (C.M.C.), surfactant molecules form micelles with a well-defined aggregation number. Above the C.M.C., the number of micelles increases while the size of the micelles stays the same.<br>\n",
    "Pyrene is a hydrophobic fluorescent molecule. In an aqueous SDS solution at [SDS]>C.M.C., pyrene partitions into the hydrophobic interior of the micelles.<br>\n",
    "The fluorescence intensity decay of pyrene following an excitation impulse is given by<br>\n",
    "$F(t)=F(0)exp(-t/\\tau_0)$<br>\n",
    "where $\\tau_0$ is the lifetime of the fluorophore.\n",
    "Fluorescence counts follows Poisson's statistics, therefore the error in $F(t)$ is simply $\\sqrt{F(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fluorescence Quenching by Benzophenone\n",
    "Benzophenone is a hydrophobic compound which quenches the fluorescence of pyrene in the micelles. \n",
    "The fluorescence intensity decay of pyrene in the presence of benzophenone is given by<br>\n",
    "$F(t)=F(0)exp\\{-t/\\tau_0-m[1-exp(-k_qt)]\\}$<br>\n",
    "where $m$ is average number of quenchers per micelle while $k_q$ is the quenching constant.<br>\n",
    "Here, we perform a global fit on the fluorescence intensity decays of pyrene in SDS dispersions containing increasing concentrations of benzophenone.<br>\n",
    "We obtain the fitting parameters $F(0)$, $\\tau_0$, $m$, and $k_q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The data are tab-separated values (TSV) files (collected from [Prof. L. Stella Lab](http://www.stc.uniroma2.it/physchem/stella.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!head -n 13 'data/fluorescence/quencher_0.0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!ls 'data/fluorescence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    t,F = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=True, skiprows=9)\n",
    "    plt.errorbar(t, F, np.sqrt(F), lw=0, marker='o', label='{:1.1f}'.format(conc)+' mM',\n",
    "                 ms=4, elinewidth=1., capsize=3, capthick=1., mfc='w')\n",
    "plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    d = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=False, skiprows=9)\n",
    "    d = d[ d[:,0] > d[d[:,1]==d[:,1].max(), 0] ] # points before the intesity max are discarded\n",
    "    plt.errorbar(d[:,0]-d[0,0], d[:,1], np.sqrt(d[:,1]), lw=0, marker='o', label='{:1.1f}'.format(conc)+' mM',\n",
    "                 ms=4, elinewidth=1., capsize=3, capthick=1., mfc='w')\n",
    "plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A convenient way to save data sets to file is to use [pickling](https://docs.python.org/3/library/pickle.html). We create a  `pandas` `DataFrame` and we save it as a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# first we generate a dictionary\n",
    "data = {}\n",
    "for conc in [0,0.2,0.5,1.0,1.5]:\n",
    "    d = np.loadtxt('data/fluorescence/quencher_{:1.1f}.txt'.format(conc), unpack=False, skiprows=9)\n",
    "    d = d[ d[:,0] > d[d[:,1]==d[:,1].max(), 0] ] # points before the intesity max are discarded\n",
    "    data[conc] = { 't': d[:,0]-d[0,0], 'F': d[:,1], 'Ferr': np.sqrt(d[:,1]) }\n",
    "# then a dataframe is generated from the dictionary\n",
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.to_pickle('data/fluorescence.p')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The curve for [quencher]=0 mM is fitted to a single exponential decay using [`optimize.least_square`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html)\n",
    "`\n",
    "least_squares(function_to_minimize, initial_params, \n",
    "    [x, y, yerr], bounds=[(lower_bounds),(upper_bounds)])\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# we load the data from the pickle file\n",
    "d = pd.read_pickle('data/fluorescence.p')[0.0]\n",
    "args = [ d['t'], d['F'], d['Ferr'] ] # list containing x, y, yerr\n",
    "# we define the exponential decay\n",
    "def func(x, param):\n",
    "    return param[0] * np.exp( - x / param[1] ) \n",
    "# we define the function that calculates the residuals\n",
    "def leastsq_function(param, *args):\n",
    "    return ( args[1] - func(args[0], param) ) / args[2] # residuals weighted by the error on y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# we fit the data\n",
    "res = least_squares(leastsq_function, x0=[3000,150], args=args, bounds=[(6,150),(3500,200)])\n",
    "plt.errorbar(args[0],args[1],args[2],lw=0,marker='o',ms=1,elinewidth=1.,capsize=3,capthick=1.,\n",
    "             color='k',alpha=0.3)\n",
    "plt.plot(args[0],func(args[0],res['x']),lw=3,color='r')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('$\\ln F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "table = r\"\"\"| Parameter     | Value         | Error |\n",
    "| :---------------- |:-------------:| :----:|\n",
    "| $F(0)$ (counts)   | %.2f          | ?     |\n",
    "| $\\tau_0$ (ns)     | %.2f          | ?     |\"\"\"\n",
    "\n",
    "display.Markdown(table % tuple(res.x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Is one of the convergence criteria satisfied?', res.success) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Comparison between gaussian with $\\sigma=1$ and $\\mu=0$ and the histogram of the residuals at solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(res.fun.min(),res.fun.max()+1,100)\n",
    "plt.plot(bins,np.exp(-bins*bins/2)/np.sqrt(2*np.pi),label='Gaussian',color='k')\n",
    "plt.hist(res.fun, bins, lw=2, histtype='step',normed=True,label='residuals',color='r')\n",
    "plt.xlabel('Residuals'); plt.ylabel('Probability Distribution')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Estimating the Goodness of Fit and the Errors in the Fitting Parameters [(as in `optimize.curve_fit`)](https://github.com/scipy/scipy/blob/2526df72e5d4ca8bad6e2f4b3cbdfbc33e805865/scipy/optimize/minpack.py#L739)\n",
    "We estimate the reduced chi squared, $\\chi^2_R$, by summing over the square of the residuals at the solution and dividing by the degrees of freedom (number of points - number of parameters).<br>\n",
    "Best-fit parameters uncertainties are estimated from the variance-covariance matrix.<br>\n",
    "Further information [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) and [here](http://scipy-cookbook.readthedocs.io/items/FittingData.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "# copied from curve_fit \n",
    "def error_analysis(res):\n",
    "    cost = 2 * res.cost  # res.cost is half sum of squares!\n",
    "    s_sq = cost / (res.fun.size - res.x.size) # residual variance or reduced chi squared\n",
    "    # Do Moore-Penrose inverse discarding zero singular values.\n",
    "    _, s, VT = svd(res.jac, full_matrices=False)\n",
    "    threshold = np.finfo(float).eps * max(res.jac.shape) * s[0]\n",
    "    s = s[s > threshold]\n",
    "    VT = VT[:s.size]\n",
    "    pcov = np.dot(VT.T / s**2, VT) * s_sq # variance-covariance matrix\n",
    "    return np.sqrt(np.diag(pcov)), s_sq # errors on the params are the diagonal elements of pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "table = r\"\"\"| Parameter     | Value         | Error |\n",
    "| :---------------- |:-------------:| :----:|\n",
    "| $F(0)$ (counts)   | %.0f          | %.0f  |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f  |\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_and_err = np.repeat(res.x, 2)\n",
    "p_and_err[1::2] = error_analysis(res)[0]\n",
    "print('Reduced chi squared:',error_analysis(res)[1])\n",
    "display.Markdown(table % tuple(p_and_err) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "####  Task: Fit the data for [quencher]=0 using `optimize.curve_fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def func(x, F0, tau0):\n",
    "    return F0 * np.exp( - x / tau0 ) \n",
    "popt,pcov = curve_fit(func, args[0], args[1], sigma=args[2], p0=[3000,150], bounds=[(6,150),(3500,200)])\n",
    "plt.errorbar(args[0],args[1],args[2],lw=0,marker='o',ms=1,elinewidth=1.,capsize=3,capthick=1.,color='k',alpha=0.3)\n",
    "plt.plot(args[0],func(args[0],popt[0],popt[1]),lw=3,color='r')\n",
    "plt.yscale('log'); plt.ylabel('$\\ln F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "table = r\"\"\"| Parameter     | Value         | Error |\n",
    "| :---------------- |:-------------:| :----:|\n",
    "| $F(0)$ (counts)   | %.0f          | %.0f  |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f  |\"\"\"\n",
    "\n",
    "p_and_err = np.repeat(popt, 2)\n",
    "p_and_err[1::2] = np.sqrt(np.diag(pcov))\n",
    "display.Markdown(table % tuple(p_and_err) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Global Fit of the 5 curves with increasing [quencher]: $F(0)$, $\\tau_0$, $k_q$ are global parameters while $m$ depends on [quencher]\n",
    "* we create 3 `list`s (for x, y, and yerr) each containing 5 `NumPy` arrays (for the 5 curves)\n",
    "* we create a `list` called $args$ containing the 3 `list`s ($allx$, $ally$, $allyerr$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/fluorescence.p')\n",
    "allx = []; ally = []; allyerr = [] # three empty lists\n",
    "for conc in data.columns:\n",
    "    allx.append(data[conc]['t']); ally.append(data[conc]['F']); allyerr.append(data[conc]['Ferr'])\n",
    "args = allx, ally, allyerr # args is a list of three lists containing 5 numpy arrays\n",
    "param0 = [3000, 160, 0.04, 0] + [0.5]*4 # initial parameters\n",
    "lbound = [0, 0, 0] + [0]*5              # lower bound\n",
    "ubound = [4000, 200, 1, 1e-5] + [3]*4   # upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In `leastsq_function`, we calculate the residuals for each curve which are assembled in a 1D `NumPy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# we define the function for the intensity decay\n",
    "def func(x, param):\n",
    "    return param[0]*np.exp( - x/param[1] + param[3]*np.expm1(-param[2]*x) ) \n",
    "# we define the function that calculates the least squares\n",
    "def leastsq_function(p, *args):\n",
    "    residuals = np.empty(0)\n",
    "    for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        r = ( args[1][i] - func(args[0][i], param) ) / args[2][i]\n",
    "        residuals = np.append(residuals, r)\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "res = least_squares(leastsq_function, x0=param0, args=args, bounds=[lbound,ubound])\n",
    "c = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "p = res['x']\n",
    "for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        plt.errorbar(args[0][i],args[1][i],args[2][i],lw=0,marker='o',\n",
    "                 ms=4,elinewidth=1.,capsize=3,capthick=1.,mfc='w',alpha=0.2)\n",
    "        plt.plot(args[0][i],func(args[0][i],param),lw=3,color=c[i],label='{:1.1f}'.format(data.columns[i])+' mM')\n",
    "plt.yscale('log'); plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$\\ln F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "table = r\"\"\"| Parameter     | Value         | Error     |\n",
    "| :---------------- |:-------------:| :-------:|\n",
    "| $F(0)$ (counts)   | %.0f          | %.0f     |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f     |\n",
    "| $k_q$ (ns$^{-1}$) | %.4f          | %.4f     |\n",
    "| $m_0$             | %.3f          | %.3f     |\n",
    "| $m_1$             | %.3f          | %.3f     |\n",
    "| $m_2$             | %.3f          | %.3f     |\n",
    "| $m_3$             | %.3f          | %.3f     |\n",
    "| $m_4$             | %.3f          | %.3f     |\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_and_e = np.repeat(res['x'],2)\n",
    "p_and_e[1::2] = error_analysis(res)[0]\n",
    "print('Reduced chi squared:',error_analysis(res)[1])\n",
    "display.Markdown(table % tuple(p_and_e) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Task: Take the $\\ln$ of each curve and perform a global fit to $\\ln F(t) = \\ln F(0) - t/\\tau_0 + m [\\exp(-k_q t) -1]$ using `least_square`.\n",
    "* modify the `NumPy` arrays in args[1] by taking the `np.log`\n",
    "* modify the `NumPy` arrays in args[2] according to the error propagation rule: error$(\\ln F)$ = error($F$) / $F$\n",
    "* define a new fitting function for the linearized equation \n",
    "* fitting and plotting can be carried out exactly as in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# we modify y and yerr in args\n",
    "for i in range( data.columns.size ):\n",
    "    args[2][i] = args[2][i]/args[1][i]\n",
    "    args[1][i] = np.log(args[1][i]) \n",
    "\n",
    "# we define the function for the linearized intensity decay\n",
    "def func(x, param):\n",
    "    return param[0] - x/param[1] + param[3]*np.expm1(-param[2]*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "res = least_squares(leastsq_function, x0=param0, args=args, bounds=[lbound,ubound])\n",
    "c = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "p = res.x\n",
    "for i,m in enumerate(p[3:]):\n",
    "        param = p[0], p[1], p[2], m\n",
    "        plt.errorbar(args[0][i],args[1][i],args[2][i],lw=0,marker='o',\n",
    "                 ms=4,elinewidth=1.,capsize=3,capthick=1.,mfc='w',alpha=0.2)\n",
    "        plt.plot(args[0][i],func(args[0][i],param),lw=3,color=c[i],label='{:1.1f}'.format(data.columns[i])+' mM')\n",
    "plt.legend(title='[quencher]',labelspacing=.7)\n",
    "plt.ylabel('$\\ln F(t)$ / counts'); plt.xlabel('$t$ / ns'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "table = r\"\"\"| Parameter     | Value         | Error     |\n",
    "| :---------------- |:-------------:| :-------:|\n",
    "| $F(0)$ (counts)   | %.3f          | %.3f     |\n",
    "| $\\tau_0$ (ns)     | %.1f          | %.1f     |\n",
    "| $k_q$ (ns$^{-1}$) | %.4f          | %.4f     |\n",
    "| $m_0$             | %.3f          | %.3f     |\n",
    "| $m_1$             | %.3f          | %.3f     |\n",
    "| $m_2$             | %.3f          | %.3f     |\n",
    "| $m_3$             | %.3f          | %.3f     |\n",
    "| $m_4$             | %.3f          | %.3f     |\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_and_e = np.repeat(res['x'],2)\n",
    "p_and_e[1::2] = error_analysis(res)[0]\n",
    "print('Reduced chi squared:',error_analysis(res)[1])\n",
    "display.Markdown(table % tuple(p_and_e) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'Value':res.x,'Error':error_analysis(res)[0]},\n",
    "             index=['$F(0)$ (counts)','$\\tau_0$ (ns)','$k_q$ (ns$^{-1}$)','$m_0$','$m_1$','$m_2$','$m_3$','$m_4$'],\n",
    "            columns=['Value','Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
